# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FD_BSGM_oe-p2Lzgb1JQaCN2axZ6xN-i
"""

import zipfile
import os

# Assuming the ZIP file is uploaded to the root directory
zip_file_path = '/content/Vehicle_Detection_Image_Dataset.zip'
extract_dir = '/content/Vehicle_Detection_Image_Dataset'

# Unzip the dataset
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

# List files to confirm extraction
os.listdir(extract_dir)

data_yaml = """
train: /content/Vehicle_Detection_Image_Dataset/Vehicle_Detection_Image_Dataset/train
val: /content/Vehicle_Detection_Image_Dataset/Vehicle_Detection_Image_Dataset/valid

nc: 1
names: ['Vehicle']
"""

# Write the yaml configuration to a file
with open('/content/Vehicle_Detection_Image_Dataset/data.yaml', 'w') as f:
    f.write(data_yaml)

# Start training
!python /content/yolov5/train.py --img 640 --batch 16 --epochs 10 --data /content/Vehicle_Detection_Image_Dataset/data.yaml --weights yolov5s.pt --cache

import matplotlib.pyplot as plt
import numpy as np

# Path to the results.csv file
results_file = '/content/yolov5/runs/train/exp2/results.csv'

# Load the results
results = np.loadtxt(results_file, delimiter=',', skiprows=1)

# Plot training and validation loss
plt.figure(figsize=(10,5))
plt.plot(results[:, 0], results[:, 1], label='train/box_loss')
plt.plot(results[:, 0], results[:, 2], label='train/obj_loss')
plt.plot(results[:, 0], results[:, 3], label='train/cls_loss')
plt.plot(results[:, 0], results[:, 4], label='val/box_loss')
plt.plot(results[:, 0], results[:, 5], label='val/obj_loss')
plt.plot(results[:, 0], results[:, 6], label='val/cls_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

# Plot mAP (mean Average Precision)
plt.figure(figsize=(10,5))
plt.plot(results[:, 0], results[:, 7], label='metrics/mAP_0.5')
plt.plot(results[:, 0], results[:, 8], label='metrics/mAP_0.5:0.95')
plt.xlabel('Epochs')
plt.ylabel('mAP')
plt.legend()
plt.title('Mean Average Precision')
plt.show()

import torch
from PIL import Image

# Load the trained model
model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp2/weights/best.pt')

# Load and test a sample image
img = Image.open('/content/Vehicle_Detection_Image_Dataset/Vehicle_Detection_Image_Dataset/sample_image.jpg')
results = model(img)
results.show()

import cv2

# Load your trained YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'custom', path='runs/train/exp2/weights/best.pt')

# Open the input video file
cap = cv2.VideoCapture('/content/Vehicle_Detection_Image_Dataset/Vehicle_Detection_Image_Dataset/sample_video.mp4')

# Get the width and height of the video frames
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Define the codec and create a VideoWriter object to save the output video
output_path = '/content/Vehicle_Detection_Image_Dataset/Vehicle_Detection_Image_Dataset/output_video.mp4'
out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 20, (frame_width, frame_height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Perform inference on the frame
    results = model(frame)

    # Render the results (draw bounding boxes and labels)
    results.render()

    # Write the processed frame to the output video file
    out.write(frame)

    # Optionally, you can display the frame with detections
    cv2.imshow('Frame', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release everything when the job is finished
cap.release()
out.release()
cv2.destroyAllWindows()

print(f"Output video saved to {output_path}")

from google.colab import files
files.download('runs/train/exp/weights/best.pt')

import matplotlib.pyplot as plt
import numpy as np

# Path to the results.txt file
results_file = 'runs/train/exp/results.csv'

# Load the results
results = np.loadtxt(results_file, delimiter=',')

# Plot the training loss
plt.figure(figsize=(10,5))
plt.plot(results[:, 0], results[:, 1], label='train/box_loss')
plt.plot(results[:, 0], results[:, 2], label='train/obj_loss')
plt.plot(results[:, 0], results[:, 3], label='train/cls_loss')
plt.plot(results[:, 0], results[:, 4], label='val/box_loss')
plt.plot(results[:, 0], results[:, 5], label='val/obj_loss')
plt.plot(results[:, 0], results[:, 6], label='val/cls_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

# Plot mAP (mean Average Precision)
plt.figure(figsize=(10,5))
plt.plot(results[:, 0], results[:, 7], label='metrics/mAP_0.5')
plt.plot(results[:, 0], results[:, 8], label='metrics/mAP_0.5:0.95')
plt.xlabel('Epochs')
plt.ylabel('mAP')
plt.legend()
plt.title('Mean Average Precision')
plt.show()

import cv2
from google.colab.patches import cv2_imshow

# Display an example of a validation result
img = cv2.imread('runs/train/exp/test_batch0_labels.jpg')
cv2_imshow(img)